{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahPangUCSB/CS263_HW1/blob/main/CS_263_Winter_2026_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol3ycAtObNad"
      },
      "source": [
        "# CS 263 Assignment 1: Transformer and LLMs for Natural Language Inference (NLI)\n",
        "\n",
        "## Deadline: 11:59 PM, Jan 26, 2026\n",
        "\n",
        "\n",
        "## Outline\n",
        "- Part 1: Transformer Implementation (55 points)\n",
        "- Part 2: Training and Evaluation via Huggingface Transformer (45 points)\n",
        "\n",
        "## Instructions\n",
        "- Follow the instructions and fill in the code for the sections marked with `# TODO`.\n",
        "- **DO NOT** modify the checking/grading cells. Modifying these cells is strictly prohibited and will be treated as an academic integrity violation which will result in 0 score for this assignment and escalation to The Office of Student Conduct at UCLA.\n",
        "- This assignment could be completed on Google Colab with the Free-Tier T4 GPU. That being said, feel free to use your own compute resources.\n",
        "- We encourage you to start early, as some parts may take additional time (e.g. requesting access to a gated LLM on HuggingFace).\n",
        "\n",
        "## Submission\n",
        "- **Execution**: Ensure all cells have been run, and outputs are displayed before submission.\n",
        "- **File Naming**: Save and download your completed notebook with outputs exactly as `hw1.ipynb`.\n",
        "- **Upload**: Submit your `hw1.ipynb` file to Gradescope.\n",
        "\n",
        "Failure to follow these instructions will result in the autograder failing, which will automatically result in 0 points. **No regrading will be done** for submissions with incorrect file names or formats.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DaTBFhBG2m0"
      },
      "source": [
        "## Part 1: Transformer Implementation (55 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30zB9u-AnQ_0"
      },
      "source": [
        "### Section 1: Scaled Dot-Product Attention (15 points)\n",
        "\n",
        "In this section, you'll implement the **generalized Scaled Dot-Product Self-Attention** mechanism as taught in the class. This is a core component of the Transformer model. This generalized version can accommodate encoder-only, decoder-only and encoder-decoder Transformer architectures, which means it supports cases where the lengths of the queries (Q) and key-value pairs (K, V) may **differ**. This is crucial for tasks like machine translation, where the encoder and decoder operate over sequences of different lengths.\n",
        "\n",
        "\n",
        "This mechanism takes four inputs: queries (Q), keys (K), values (V), and attention masks. It computes attention weights based on the dot product of Q and K, scaled by the square root of the dimensionality of the keys. This helps stabilize gradients and improve model performance. Once the attention weights are calculated, they are used to combine the values (V) into a weighted sum.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G8_dkDJJC22Z"
      },
      "outputs": [],
      "source": [
        "# DO NOT alter this cell\n",
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ABY9ByrbINV0"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "    # Q: FloatTensor of shape (bsz, q_len, d)\n",
        "    # K, V: FloatTensor of shape (bsz, kv_len, d)\n",
        "    # mask: optional, BoolTensor of shape (bsz, q_len, kv_len)\n",
        "    # return: outputs, attention_weights\n",
        "    #   outputs: FloatTensor of shape (bsz, q_len, d), output of attention module\n",
        "    #   attention_weights: FloatTensor of shape (bsz, q_len, kv_len), attention weights between 0-1\n",
        "\n",
        "    # Hint: if mask[i, j, k] is False, that means for the i-th data point in the batch,\n",
        "    #   the attention weight from j-th position in Q to k-th position in KV is zero.\n",
        "    #   To do that, you can set the attention logits to a very small value like -np.inf before feeding to softmax\n",
        "\n",
        "    dot_prod = torch.matmul(q, k.transpose(-2, -1))  # (bsz, q_len, kv_len)\n",
        "    scaled_dot_prod = dot_prod / math.sqrt(q.size(-1))\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_dot_prod = scaled_dot_prod.masked_fill(mask==False, -np.inf)\n",
        "\n",
        "    attention_weights = torch.softmax(scaled_dot_prod, dim=-1)\n",
        "    outputs = torch.matmul(attention_weights, v)\n",
        "\n",
        "    return outputs, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79QcPjegJ3WJ"
      },
      "source": [
        "You can use the following section to check your implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2xYw7TJNIQhV",
        "outputId": "845688f6-bc16-45ab-945f-df91a8680bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the output shape is torch.Size([2, 5, 3])\n",
            "the shape of attention weight (torch.Size([2, 5, 4])) should be the batch x query x key = 2 x 5 x 4\n",
            "Part 1.1.1.a passed\n",
            "\n",
            "Checking that attention weights sum to 1 across the key dimension (kv_len).\n",
            "Part 1.1.1.b passed\n",
            "\n",
            "Checking that our implementation produces the same results as PyTorch's built-in function.\n",
            "Part 1.1.1.c passed\n",
            "\n",
            "Ensuring that positions excluded by the mask have nearly zero attention values.\n",
            "Part 1.1.2.a passed\n",
            "\n",
            "Verifying that our masked attention output matches PyTorch's built-in function with the mask applied.\n",
            "Part 1.1.2.b passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "# Verify shape\n",
        "bsz, q_len, kv_len, d = 2, 5, 4, 3\n",
        "q = torch.randn(bsz, q_len, d)\n",
        "k = torch.randn(bsz, kv_len, d)\n",
        "v = torch.randn(bsz, kv_len, d)\n",
        "values, attention = scaled_dot_product_attention(q, k, v)\n",
        "print(f\"the output shape is {values.shape}\")\n",
        "print(f\"the shape of attention weight ({attention.shape}) should be the batch x query x key = {bsz} x {q_len} x {kv_len}\")\n",
        "assert tuple(attention.shape) == (bsz, q_len, kv_len)\n",
        "print(\"Part 1.1.1.a passed\")\n",
        "print()\n",
        "print(\"Checking that attention weights sum to 1 across the key dimension (kv_len).\")\n",
        "assert attention.sum(-1).allclose(torch.ones(bsz, q_len, ))\n",
        "print(\"Part 1.1.1.b passed\")\n",
        "print()\n",
        "print(\"Checking that our implementation produces the same results as PyTorch's built-in function.\")\n",
        "assert values.allclose(F.scaled_dot_product_attention(q, k, v, attn_mask=None))\n",
        "print(\"Part 1.1.1.c passed\")\n",
        "print()\n",
        "# Verify attention mask's function\n",
        "bsz, q_len, kv_len, d = 2, 5, 4, 3\n",
        "q = torch.randn(bsz, q_len, d)\n",
        "k = torch.randn(bsz, kv_len, d)\n",
        "v = torch.randn(bsz, kv_len, d)\n",
        "mask = torch.rand(bsz, q_len, kv_len) > 0.5\n",
        "mask[:, :, 0] = True\n",
        "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "assert tuple(attention.shape) == (bsz, q_len, kv_len)\n",
        "assert attention.sum(-1).allclose(torch.ones(bsz, q_len))\n",
        "print(\"Ensuring that positions excluded by the mask have nearly zero attention values.\")\n",
        "assert (attention[~mask].abs() < 1e-8).all()\n",
        "print(\"Part 1.1.2.a passed\")\n",
        "print()\n",
        "print(\"Verifying that our masked attention output matches PyTorch's built-in function with the mask applied.\")\n",
        "assert values.allclose(F.scaled_dot_product_attention(q, k, v, attn_mask=mask))\n",
        "print(\"Part 1.1.2.b passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpgNAKEFKHGU"
      },
      "source": [
        "### Section 2: Multi-head Attention (10 points)\n",
        "\n",
        "Multi-head attention allows the model to focus on different parts of the input sequence from multiple perspectives, enhancing the model's ability to capture diverse dependencies. This is achieved by using multiple attention heads, each with its own set of query, key, and value projections. The outputs from all heads are then concatenated together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VZPVZSnsKkmx"
      },
      "outputs": [],
      "source": [
        "def multi_head_attention(q, k, v, num_heads: int, mask=None):\n",
        "    # Q: FloatTensor of shape (bsz, q_len, d_model)\n",
        "    # K, V: FloatTensor of shape (bsz, kv_len, d_model)\n",
        "    # mask: optional, BoolTensor of shape (bsz, q_len, kv_len)\n",
        "    # return: outputs, attention_weights\n",
        "    #   outputs: FloatTensor of shape (bsz, q_len, d_model), output of attention module\n",
        "    #   attention_weights: FloatTensor of shape (bsz, num_heads, q_len, kv_len), attention weights between 0-1\n",
        "\n",
        "    # Hint: to perform multi-head attention, you split the `d_model`-dimension features into `num_heads` splits. Each attention head will use d_model // num_heads dimensions\n",
        "    # Hint: For example, if d_model is 12 and num_heads is 3, then the first head uses first 4 features, the second head uses 4-8 features, and the third one use last 4 features\n",
        "    # Hint: Then finally, we concatenate outputs from all heads into the output values\n",
        "    # Hint: You can call the scaled_dot_product_attention function you just implemented for each head's computation\n",
        "    # Hint: In real applications, we also want some linear layers to \"project\" the query, key and values before doing attention, but now we're omitting this step\n",
        "    assert q.shape[-1] % num_heads == 0\n",
        "\n",
        "    head_dim = q.shape[-1] // num_heads\n",
        "    q_heads = q.view(q.shape[0], q.shape[1], num_heads, head_dim).transpose(1, 2)  # (bsz, num_heads, q_len, head_dim)\n",
        "    k_heads = k.view(k.shape[0], k.shape[1], num_heads, head_dim).transpose(1, 2)  # (bsz, num_heads, kv_len, head_dim)\n",
        "    v_heads = v.view(v.shape[0], v.shape[1], num_heads, head_dim).transpose(1, 2)  # (bsz, num_heads, kv_len, head_dim)\n",
        "\n",
        "    outputs = torch.zeros_like(q_heads)\n",
        "    attention_weights = torch.zeros((q_heads.shape[0], num_heads, q_heads.shape[2], k_heads.shape[2]))\n",
        "\n",
        "    for head in range(num_heads):\n",
        "        head_outputs, head_attention_weights = scaled_dot_product_attention(q_heads[:, head], k_heads[:, head], v_heads[:, head], mask)\n",
        "        outputs[:, head] = head_outputs\n",
        "        attention_weights[:, head] = head_attention_weights\n",
        "\n",
        "    outputs = outputs.transpose(1, 2).view(q.shape[0], q.shape[1], -1)\n",
        "\n",
        "    return outputs, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsa9ElBWK111"
      },
      "source": [
        "You can use the following section to check your implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YHXxyEzYK2WG",
        "outputId": "24cbc292-92f1-4ee6-e0bf-0c4088dcbbf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the output shape is torch.Size([2, 5, 12])\n",
            "the shape of attention weight (torch.Size([2, 3, 5, 4])) should be the batch x number of attention heads x query x key(value) = 2 x 3 x 5 x 4\n",
            "Checking that attention weights sum to 1 across the key dimension (kv_len).\n",
            "Part 1.2.1.a passed\n",
            "\n",
            "Checking that our implementation produces the same results as PyTorch's built-in function.\n",
            "Part 1.2.1.b passed\n",
            "\n",
            "Part 1.2.2.a passed\n",
            "\n",
            "Ensuring that positions excluded by the mask have nearly zero attention values.\n",
            "Verifying that our masked attention output matches PyTorch's built-in function with the mask applied.\n",
            "Part 1.2.2.b passed\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "# Verify shape\n",
        "bsz, q_len, kv_len, d, num_heads = 2, 5, 4, 12, 3\n",
        "q = torch.randn(bsz, q_len, d)\n",
        "k = torch.randn(bsz, kv_len, d)\n",
        "v = torch.randn(bsz, kv_len, d)\n",
        "values, attention = multi_head_attention(q, k, v, num_heads=num_heads)\n",
        "print(f\"the output shape is {values.shape}\")\n",
        "print(f\"the shape of attention weight ({attention.shape}) should be the batch x number of attention heads x query x key(value) = {bsz} x {num_heads} x {q_len} x {kv_len}\")\n",
        "assert tuple(attention.shape) == (bsz, num_heads, q_len, kv_len)\n",
        "print(\"Checking that attention weights sum to 1 across the key dimension (kv_len).\")\n",
        "assert attention.sum(-1).allclose(torch.ones(bsz, num_heads, q_len))\n",
        "print(\"Part 1.2.1.a passed\")\n",
        "print()\n",
        "print(\"Checking that our implementation produces the same results as PyTorch's built-in function.\")\n",
        "standard_values, standard_attention = F.multi_head_attention_forward(\n",
        "    q.permute(1, 0, 2), k.permute(1, 0, 2), v.permute(1, 0, 2),\n",
        "    embed_dim_to_check=d, num_heads=num_heads, attn_mask=None,\n",
        "    use_separate_proj_weight=True, in_proj_weight=None, in_proj_bias=None,\n",
        "    q_proj_weight=torch.eye(d), k_proj_weight=torch.eye(d), v_proj_weight=torch.eye(d),\n",
        "    out_proj_weight=torch.eye(d), out_proj_bias=torch.zeros(d),\n",
        "    add_zero_attn=False, dropout_p=0, is_causal=False,\n",
        "    bias_k=None, bias_v=None, average_attn_weights=False,\n",
        ")\n",
        "assert values.allclose(standard_values.permute(1, 0, 2))\n",
        "assert attention.allclose(standard_attention)\n",
        "print(\"Part 1.2.1.b passed\")\n",
        "print()\n",
        "# Verify attention mask's function\n",
        "bsz, q_len, kv_len, d, num_heads = 2, 5, 4, 12, 3\n",
        "q = torch.randn(bsz, q_len, d)\n",
        "k = torch.randn(bsz, kv_len, d)\n",
        "v = torch.randn(bsz, kv_len, d)\n",
        "mask = torch.rand(bsz, q_len, kv_len) > 0.5\n",
        "mask[:, :, 0] = True\n",
        "values, attention = multi_head_attention(q, k, v, num_heads=num_heads, mask=mask)\n",
        "assert tuple(attention.shape) == (bsz, num_heads, q_len, kv_len)\n",
        "assert attention.sum(-1).allclose(torch.ones(bsz, num_heads, q_len))\n",
        "print(\"Part 1.2.2.a passed\")\n",
        "print()\n",
        "\n",
        "print(\"Ensuring that positions excluded by the mask have nearly zero attention values.\")\n",
        "assert (attention.sum(1)[~mask].abs() < 1e-8).all()\n",
        "standard_values, standard_attention = F.multi_head_attention_forward(\n",
        "    q.permute(1, 0, 2), k.permute(1, 0, 2), v.permute(1, 0, 2),\n",
        "    embed_dim_to_check=d, num_heads=num_heads, attn_mask=(~mask).repeat_interleave(num_heads, dim=0),\n",
        "    use_separate_proj_weight=True, in_proj_weight=None, in_proj_bias=None,\n",
        "    q_proj_weight=torch.eye(d), k_proj_weight=torch.eye(d), v_proj_weight=torch.eye(d),\n",
        "    out_proj_weight=torch.eye(d), out_proj_bias=torch.zeros(d),\n",
        "    add_zero_attn=False, dropout_p=0, is_causal=False,\n",
        "    bias_k=None, bias_v=None, average_attn_weights=False,\n",
        ")\n",
        "print(\"Verifying that our masked attention output matches PyTorch's built-in function with the mask applied.\")\n",
        "assert values.allclose(standard_values.permute(1, 0, 2))\n",
        "assert attention.allclose(standard_attention)\n",
        "print(\"Part 1.2.2.b passed\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMg6QZviLlW9"
      },
      "source": [
        "Below is an overall architecture of transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xkronCl8Lly8"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        # Original Transformer initialization, see PyTorch documentation\n",
        "        nn.init.xavier_uniform_(self.q_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.k_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.v_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
        "        self.q_proj.bias.data.fill_(0)\n",
        "        self.k_proj.bias.data.fill_(0)\n",
        "        self.v_proj.bias.data.fill_(0)\n",
        "        self.o_proj.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        q = self.q_proj(x)  # Note: for actual implementation, we need to do projection\n",
        "        k = self.k_proj(x)\n",
        "        v = self.v_proj(x)\n",
        "        o, _ = multi_head_attention(q, k, v, self.num_heads, mask=mask)\n",
        "        return self.o_proj(o)\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            input_dim - Dimensionality of the input\n",
        "            num_heads - Number of heads to use in the attention block\n",
        "            dim_feedforward - Dimensionality of the hidden layer in the MLP\n",
        "            dropout - Dropout probability to use in the dropout layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Attention layer\n",
        "        self.self_attn = MultiheadAttention(input_dim, num_heads)\n",
        "\n",
        "        # Two-layer MLP\n",
        "        self.linear_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, dim_feedforward),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_feedforward, input_dim)\n",
        "        )\n",
        "\n",
        "        # Layers to apply in between the main layers\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Attention part\n",
        "        attn_out = self.self_attn(x, mask=mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # MLP part\n",
        "        linear_out = self.linear_net(x)\n",
        "        x = x + self.dropout(linear_out)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, we, pe, layers):\n",
        "        super().__init__()\n",
        "        self.we = we  # word embeddings\n",
        "        self.pe = pe  # positional embeddings\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        vocab_size, model_dim = we.weight.shape\n",
        "        self.lm_head = nn.Linear(model_dim, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, tokens, mask=None):\n",
        "        x = self.we(tokens) + self.pe(tokens)\n",
        "        for l in self.layers:\n",
        "            x = l(x, mask=mask)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3jVajnLouW"
      },
      "source": [
        "### Section 3: Positional Encoding (10 points)\n",
        "\n",
        "Transformers lack an inherent sense of order in sequences, which is why positional encodings are added to the input embeddings. These encodings provide information about the position of tokens in a sequence, allowing the model to differentiate between tokens in different positions.\n",
        "\n",
        "The positional encoding for each element $PE(pos, 2i)$ and $PE(pos, 2i+1)$ is defined as follows:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "    PE(pos, 2i) & = \\sin(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}), \\\\\n",
        "    PE(pos, 2i+1) & = \\cos(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $pos$ is the position in the sequence.\n",
        "- $i$ is the dimension index (split between even and odd indices).\n",
        "- $d_{model}$ is the dimensionality of the model's input embeddings.\n",
        "\n",
        "This alternating use of sine and cosine allows each position to have a unique encoding across the dimensions, making it easier for the model to distinguish between positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "onDNWExIMO4G"
      },
      "outputs": [],
      "source": [
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, d_model, base=10000):\n",
        "        \"\"\"\n",
        "        Inputs\n",
        "            d_model - Hidden dimensionality of the input.\n",
        "            base - Base for rotary positional encodings.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.base = base\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: FloatTensor of shape (bsz, seq_len)\n",
        "        # return: pe, FloatTensor of shape (bsz, seq_len, d_model)\n",
        "        #   pe[..., i] is the positional encoding for i-th position\n",
        "        bsz, seq_len = x.shape\n",
        "\n",
        "        pe = torch.zeros(seq_len, self.d_model)\n",
        "        position = torch.arange(0, seq_len).unsqueeze(1)\n",
        "\n",
        "        two_i = torch.arange(0, self.d_model, 2)\n",
        "        argument = torch.divide(position, torch.pow(self.base, two_i/self.d_model))\n",
        "        pe[:, 0::2] = torch.sin(argument)\n",
        "        pe[:, 1::2] = torch.cos(argument[:, :self.d_model // 2])\n",
        "        self.pe = pe.unsqueeze(0).expand(bsz, -1, -1)\n",
        "\n",
        "        return pe.to(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T-yscBdaXKtG",
        "outputId": "7c71ff1d-2178-4cef-cc82-2bf7720a6457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of positional encoding torch.Size([100, 64]) should be sequence length x feature dimension = 100 x 64\n",
            "Part 1.3.1 passed\n",
            "\n",
            "The difference between encodings at different positions should be non-zero, which indicates that each position has a unique encoding\n",
            "Part 1.3.2 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "d_model = 64\n",
        "\n",
        "pe = PositionalEncodings(d_model).forward(torch.zeros(1, 100)).squeeze(0)\n",
        "print(f\"The shape of positional encoding {pe.shape} should be sequence length x feature dimension = 100 x {d_model}\")\n",
        "assert tuple(pe.shape) == (100, d_model)\n",
        "print(\"Part 1.3.1 passed\")\n",
        "print()\n",
        "print(\"The difference between encodings at different positions should be non-zero, which indicates that each position has a unique encoding\")\n",
        "diff = (pe[:, None, :] - pe[None, :, :]).abs().sum(dim=-1)\n",
        "assert (diff[~torch.eye(100).bool()] != 0).all()\n",
        "print(\"Part 1.3.2 passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B0RfzMSrNwlm",
        "outputId": "6563b946-4baf-4bb7-9841-1f3e7e628324",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerDecoder(\n",
            "  (we): Embedding(6, 64)\n",
            "  (pe): PositionalEncodings()\n",
            "  (layers): ModuleList(\n",
            "    (0-3): 4 x DecoderBlock(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (o_proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (linear_net): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): Dropout(p=0.0, inplace=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "      )\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=64, out_features=6, bias=False)\n",
            ")\n",
            "The output shape is torch.Size([2, 4, 6]). The expected output shape is batch_size x sequence_length x vocab_size = 2 x 4 x 6\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "n_vocab = 6\n",
        "d_model = 64\n",
        "num_heads = 4\n",
        "n_layers = 4\n",
        "\n",
        "model = TransformerDecoder(\n",
        "    we=nn.Embedding(n_vocab, d_model),\n",
        "    pe=PositionalEncodings(d_model),\n",
        "    layers=[\n",
        "        DecoderBlock(d_model, num_heads, dim_feedforward=2 * d_model)\n",
        "        for _ in range(n_layers)\n",
        "    ],\n",
        ").cuda()\n",
        "print(model)\n",
        "\n",
        "tokens = torch.LongTensor([\n",
        "    [0, 1, 2, 3],\n",
        "    [3, 2, 1, 0],\n",
        "]).cuda()\n",
        "out = model(tokens)\n",
        "print(f\"The output shape is {out.shape}. The expected output shape is batch_size x sequence_length x vocab_size = 2 x 4 x {n_vocab}\")\n",
        "assert tuple(out.shape) == (tokens.shape[0], tokens.shape[1], n_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS564L27evsM"
      },
      "source": [
        "### Section 4: Autoregressive Attention Mask (5 points)\n",
        "\n",
        "In this function, you will implement an autoregressive attention mask, which is essential for language modeling tasks where each token can only attend to itself and the tokens that precede it. This prevents the model from \"peeking\" at future tokens, thus preserving the autoregressive property of the model.\n",
        "\n",
        "The autoregressive attention mask (also called as causal attention mask) should be a lower triangular matrix. In other words, the mask is True for positions on or below the diagonal and False for positions above the diagonal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_sLLsFaqexbn"
      },
      "outputs": [],
      "source": [
        "def autoregressive_attention_mask(tokens):\n",
        "    # tokens: (bsz, seq_len)\n",
        "    # return: mask, torch.BoolTensor of shape (bsz, seq_len as q_len, seq_len as kv_len)\n",
        "    # Hint: generate an autoregressive attention mask. mask[i, j, k] is True means j-th token can attend to k-th token\n",
        "    #   For autoregressive language modelling task, each position can only attend to itself and its previous tokens, and cannot \"cheat\" and peak future tokens\n",
        "    bsz, seq_len = tokens.shape\n",
        "\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len)) == 1\n",
        "    mask = mask.unsqueeze(0).expand(bsz, -1, -1)\n",
        "\n",
        "    return mask.to(tokens.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kYbdNgpffRmm",
        "outputId": "91894a2b-0d1f-4ec5-df61-5ebd40291dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking shape: expected (2, 10, 10), got torch.Size([2, 10, 10])\n",
            "Checking data type: expected torch.bool, got torch.bool\n",
            "Part 1.4 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "mask = autoregressive_attention_mask(torch.zeros(2, 10))\n",
        "print(f\"Checking shape: expected (2, 10, 10), got {mask.shape}\")\n",
        "assert tuple(mask.shape) == (2, 10, 10)\n",
        "print(f\"Checking data type: expected torch.bool, got {mask.dtype}\")\n",
        "assert mask.dtype == torch.bool\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i >= j:\n",
        "            assert mask[:, i, j].all()\n",
        "        else:\n",
        "            assert not mask[:, i, j].any()\n",
        "\n",
        "print(\"Part 1.4 passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6658EdvQShfK"
      },
      "source": [
        "### Section 5: Language Modeling Objective (15 points)\n",
        "\n",
        "The language modeling loss is commonly used in tasks where the goal is to predict the next word in a sequence. This loss measures the difference between the predicted probabilities of the model and the actual word in the sequence. For this task, cross-entropy loss is often used as it compares the predicted distribution with the true one-hot encoded distribution.\n",
        "Note: Since we are doing next token predictions, **Remember to shift the tokens to get the actual labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1aUD2OMnSU0H"
      },
      "outputs": [],
      "source": [
        "def language_modelling_loss(tokens, logits):\n",
        "    # tokens: (bsz, seq_len)\n",
        "    # logits: (bsz, seq_len, n_vocab) raw logits predicted from `logits = self.lm_head(x)`\n",
        "    # return: loss, a torch scalar.\n",
        "    # Hint: use https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "    #   Since language modelling is essentially a self supervision task, you can create labels from input tokens itself\n",
        "    #   Remember to shift the tokens to get the actual labels\n",
        "\n",
        "    # TODO:\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss(logits[:, :-1].reshape(-1, logits.shape[-1]), tokens[:, 1:].reshape(-1))\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "86GFzvauS_jP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76bb781-85fb-47e9-b196-af3edd6dbf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking if the loss is a scalar. Expected shape: (), got torch.Size([])\n",
            "Part 1.5.1 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "loss = language_modelling_loss(tokens, out)\n",
        "print(f\"Checking if the loss is a scalar. Expected shape: (), got {loss.shape}\")\n",
        "\n",
        "assert tuple(loss.shape) == ()\n",
        "print(\"Part 1.5.1 passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfmMe9D7TKlO"
      },
      "source": [
        "Now let's train our implemented Transformer with a naive task: predicting the next number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NYqjSjL8TXWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "704ec82c-f14b-41a7-f82c-fbc919ed6ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-785691618.py:11: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  return float(loss)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: loss = 1.9695\n",
            "Step 101: loss = 0.1043\n",
            "Step 201: loss = 0.0389\n",
            "Step 301: loss = 0.0244\n",
            "Step 401: loss = 0.0178\n",
            "Step 501: loss = 0.0139\n",
            "Step 601: loss = 0.0113\n",
            "Step 701: loss = 0.0095\n",
            "Step 801: loss = 0.0081\n",
            "Step 901: loss = 0.0069\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "def train_step(model, optimizer, tokens):\n",
        "    model.zero_grad()\n",
        "    model.train()\n",
        "    mask = autoregressive_attention_mask(tokens)\n",
        "    logits = model(tokens, mask)\n",
        "    loss = language_modelling_loss(tokens, logits)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "# Let's use a very naive data to try training: predict the next number\n",
        "tokens = torch.LongTensor([\n",
        "    [0, 1, 2, 3],\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 3, 4, 5],\n",
        "    [5, 4, 3, 2],\n",
        "    [4, 3, 2, 1],\n",
        "    [3, 2, 1, 0],\n",
        "]).cuda()\n",
        "\n",
        "# re-initialize the model, in case the cell is executed multiple times\n",
        "model = TransformerDecoder(\n",
        "    we=nn.Embedding(n_vocab, d_model),\n",
        "    pe=PositionalEncodings(d_model),\n",
        "    layers=[\n",
        "        DecoderBlock(d_model, num_heads, dim_feedforward=2 * d_model)\n",
        "        for _ in range(n_layers)\n",
        "    ],\n",
        ").cuda()\n",
        "\n",
        "# train\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "losses = []\n",
        "for i in range(1000):\n",
        "    loss = train_step(model, optimizer, tokens)\n",
        "    if i % 100 == 0:\n",
        "        print(\"Step {:d}: loss = {:.4f}\".format(i + 1, loss))\n",
        "    losses.append(loss)\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tG74SnNoTcwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10a00c1-6c17-4744-c517-c99ef41f0eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next token of 1, 2, 3:\n",
            "  p(4) = 0.9945\n",
            "  p(3) = 0.0013\n",
            "  p(1) = 0.0012\n",
            "Part 1.5.2.a passed\n",
            "\n",
            "Next token of 3, 2, 1:\n",
            "  p(0) = 0.9885\n",
            "  p(5) = 0.0033\n",
            "  p(1) = 0.0027\n",
            "\n",
            "Part 1.5.2.b passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell\n",
        "\n",
        "tokens = torch.LongTensor([\n",
        "    [1, 2, 3],\n",
        "    [3, 2, 1],\n",
        "]).cuda()\n",
        "mask = autoregressive_attention_mask(tokens)\n",
        "logits = model(tokens, mask)\n",
        "prob = nn.Softmax(dim=-1)(logits)\n",
        "\n",
        "print(\"Next token of 1, 2, 3:\")\n",
        "for j in prob[0, -1].argsort(descending=True)[:3]:\n",
        "    print(\"  p({:d}) = {:.4f}\".format(j, prob[0, -1, j]))\n",
        "assert (prob[0, -1].argsort(descending=True)[0] == 4)\n",
        "print(\"Part 1.5.2.a passed\")\n",
        "print()\n",
        "print(\"Next token of 3, 2, 1:\")\n",
        "for j in prob[1, -1].argsort(descending=True)[:3]:\n",
        "    print(\"  p({:d}) = {:.4f}\".format(j, prob[1, -1, j]))\n",
        "assert (prob[1, -1].argsort(descending=True)[0] == 0)\n",
        "print()\n",
        "print(\"Part 1.5.2.b passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7gZz3NPhgqGe"
      },
      "outputs": [],
      "source": [
        "# run this cell before moving into part2 to clear up gpu memory\n",
        "del model\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDMA8eC3VPoq"
      },
      "source": [
        "## Part 2: Training and Evaluation via Huggingface Transformer (45 points)\n",
        "\n",
        "In this part, you will first implement the evaluation of a transformer model on a dataset and then fine-tune the model to observe improvements on task performance.\n",
        "\n",
        "Hints:\n",
        "- You can use a GPU to speed up the training process. Select \"Runtime\" > \"Change runtime type\" > \"GPU\" in the Colab settings.\n",
        "- Use smaller batch sizes if you encounter memory issues.\n",
        "\n",
        "### Prerequisites: Install Libraries and Login to HuggingFace\n",
        "\n",
        "- The model we are going to use is [Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) which is a gated model. Please visit the model page on Hugging Face and accept the terms of the license. Typically, access is granted within 24 hours.\n",
        "- Go to huggingface -> Profile icon on the upper-right corner -> \"Settings\" -> \"Access Tokens\" to get the key for logging in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DmMtq-DBVs1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045028f5-be6a-45ec-b0e5-803f4006d294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m4.5/8.4 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.9.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.3)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=253780426 sha256=4e2f9e39313266b1544b68138b15b91ee6221eccf14f7902b7c6620351340810\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.8.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate bitsandbytes>0.37.0 trl==0.12.0 peft\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ELvlh-1HVvYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "ef06769e84974f6ebe27d54d065a7a28",
            "c0b53130974843e69b74aa3952294ae1",
            "e0e890eeef164c11ada76c061b4d58f6",
            "540d59488b4d4685bddadac03b20f67e",
            "c0adb79942a7448282c74e1c5d7c70bc",
            "2560557b97824838a4082904c642e331",
            "fe05f816a09944e98b0abfc9829a8527",
            "32ef54dd3d8e42c4be9e8aedcd80005b",
            "5f0c5d6bde5445f59d1d5d61a4f60fa6",
            "baf398c454a54fe7949f2b9f75be797d",
            "b0115269912b44ddb41bf3ac729c09b1",
            "f42247b447dd432ba127f37ab68039a5",
            "7db3de040d594f4ebcf6b174ef96f432",
            "212e161484b54607b60b9af8b1b34e9c",
            "34c0a5d2c2e84cbd8465d2f7a6fb6f03",
            "412138868d7744bd885441c5436f051e",
            "d144d3d180fe4ceca0040eb923c67341",
            "5d049b709c25444c970e21d66f88abed",
            "1993c46a31a64b868d4012bc8cee2de5",
            "ca796eb5797e470c9cb1a70dc221d81f"
          ]
        },
        "outputId": "a6594b4f-9ea2-42b1-f84c-43a7d197daf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef06769e84974f6ebe27d54d065a7a28"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOnP7pO6WSre"
      },
      "source": [
        "### Section 1: Loading the model and the tokenizer (15 points)\n",
        "In this section, you will learn how to load the pre-trained model and its associated tokenizer using the huggingface package.\n",
        "\n",
        "You can see a demo code here: <br>\n",
        "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vd8V6suyWg7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "6d70dfa7f27e45fea8404b83d01ea9ec",
            "d7a8ad94cbc44ef89e2cdaa547648fec",
            "4ca7c35209e541f483b20d013b76903d",
            "b686f075d1d0430e845c317137510750",
            "7642a27daaee4d64aad86957a3be786e",
            "91bd8f9fb7834523a221e1670fe048cd",
            "7b4c3d0654d34862846c6c45e5887885",
            "29c430fbb2ae464bbd40c3349ef49e5a",
            "51d2aac7fab64fe3bfdad055a65cb8cf",
            "d4d4e08473fe41d0835da8fbc0488206",
            "189cf80766b242359f0ecac8614389b0",
            "3ed8dd6693f4444bb512e83c0285a5b3",
            "9e5299d524ae4893bba196270a10070b",
            "323234ba73d44aa68f1d260b525701a6",
            "b146a20fcccb4f2e92b4a240098ac460",
            "554a80ae82374177a0e2344463706da6",
            "e0624136905f45c0b34e5d7992016a90",
            "d169c56354ca49a3a86d65c360faf777",
            "9926167ce8854b01a000cc9c263f4f9f",
            "66486d00f6544439bda1fa57d5f66cf9",
            "cb87c5d9f4d14676ad2e362eefd1014e",
            "7a9c9971d750433f92007b741cf139c1",
            "9993f055ff3b4dc585e134a022fc44b3",
            "ba25ac6cbf2f47d0a099bcb18c1c839d",
            "f5f6f5f1bcd148cba7b215d9f9c98001",
            "9b1101b480cf4ca3a3d45a887a4f694d",
            "00cd50c6d8a742e290833103ddc1a82c",
            "d2bae76ffb8e423e8fac29c0abced9ee",
            "79dcaa951c5b4af1ad43aee05745579c",
            "3cb3fefe8a444a7887587d556d50fe63",
            "fec93d20ddfb488c88b0b52c5c822e4b",
            "2b586e4ebfa54f9c8d142fc9ce2dc6d9",
            "944932c577144063a4030d8de566ef2a",
            "78de7e6563f64399ad2ca7fe751170d0",
            "16b8e8f2364c4d7084a7db22cfcc16c2",
            "ab6aafe4856b498f90d3809bb8de97ea",
            "91425cf1000049c3877e5470a7e26ac9",
            "2a7960d5b5794bc49d40e8a964cc2798",
            "1247174e2cf4457ba13ff7659cf1f3e2",
            "e08c0bf1d3d14bc9ab56e303af78db85",
            "7d40bec53dd646ecb37bb45ac6dc31d4",
            "6e888581642240d7b9f3141e05a10bc1",
            "5ac35af37262426e96a4d1559f995e37",
            "c4ab5a6c17684a0ab119d6de30fc069a",
            "c07d0c0f036b4f6786d56ca37511f574",
            "37b711afd13b46eba2a0b5388c269fcb",
            "bf34a095d0cf49858636ffb6a5cccec7",
            "5881e3b5df30436abe1f0f3a98689efc",
            "eb639ccb8a194d8b8e511fa7ae992bcf",
            "b9be5d22167c4d16a69754d225b7e63a",
            "0abe1eb5e74b4014b1f7732654218425",
            "55af65032c44427daded4bd953a3a5e4",
            "7efe83180a19491e95979f4e760ddf3c",
            "84b9ffa2d7fd4835a5c67edec3c2aeed",
            "2806c53e8b874d86a136148be4e854a7",
            "ff5e8b6ae015417ca04395a8ad2ef3a2",
            "538b2d8e900f48cf93aec9d9d8dd3ae7",
            "2bbd077e13ef4596a7e0127b429e70a8",
            "d47b7c787a3d479ab196ab8f96b49804",
            "e1f8820df7a44e199ed60a60141ea2ce",
            "5a917102eaa142c685d2e8a0a03e8809",
            "a0c2cefc18cb4ff99fa2e31c44983e8e",
            "a210f3cfde044d1c99fd69fcac6d0fbd",
            "143ccd51bf1240a08c8389248eb12e66",
            "374c960422b24aa68fd1703e2ef41462",
            "5e950ca4f60146d88f4336b67c6a0976"
          ]
        },
        "outputId": "77da68ec-aedc-4ac1-a5d9-5180da5a72a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d70dfa7f27e45fea8404b83d01ea9ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ed8dd6693f4444bb512e83c0285a5b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9993f055ff3b4dc585e134a022fc44b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78de7e6563f64399ad2ca7fe751170d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c07d0c0f036b4f6786d56ca37511f574"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff5e8b6ae015417ca04395a8ad2ef3a2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# TODO: Load the model using the appropriate parameters using AutoModelForCausalLM\n",
        "# Ensure torch_dtype is set to torch.bfloat16\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
        "\n",
        "# TODO: Initialize the tokenizer using AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-8qwn9rJfal_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9f9a8d-7097-4c8a-b24a-7ae826cbc780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The vocabulary size of the model is 128256\n",
            "Part 2.1.1 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell.\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "print(f\"\\nThe vocabulary size of the model is {vocab_size}\")\n",
        "assert vocab_size == 128256\n",
        "print(\"Part 2.1.1 passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6GghJ121-Brt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ed552b-2edd-4c8c-f76b-32bd134d50bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "###input_text:###\n",
            " <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 Jan 2026\n",
            "\n",
            "You are a chatbot who responds very shortly.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Is this a good message?<|eot_id|>\n",
            "\n",
            "###input_ids:###\n",
            " tensor([[128000, 128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,\n",
            "           2696,     25,   6790,    220,   2366,     18,    198,  15724,   2696,\n",
            "             25,    220,   1419,   4448,    220,   2366,     21,    271,   2675,\n",
            "            527,    264,   6369,   6465,    889,  31680,   1633,  20193,     13,\n",
            "         128009, 128006,    882, 128007,    271,   3957,    420,    264,   1695,\n",
            "           1984,     30, 128009]], device='cuda:0')\n",
            "\n",
            "###response:###\n",
            " This message is a good start\n",
            "\n",
            "###Assistant response:###\n",
            "This message is a good start\n"
          ]
        }
      ],
      "source": [
        "# TODO: Define the messages for the chatbot interaction (List[Dict])\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a chatbot who responds very shortly.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Is this a good message?\"},\n",
        "]\n",
        "\n",
        "def run_model(model, tokenizer, messages, max_new_tokens=5, verbose=False):\n",
        "    # TODO: Prepare the input text using the tokenizer's apply_chat_template (Do not tokenize the text yet)\n",
        "    input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    if verbose: print(\"\\n###input_text:###\\n\", input_text)\n",
        "    # TODO: Tokenize the input text and transfer it to the appropriate device\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    if verbose: print(\"\\n###input_ids:###\\n\", input_ids)\n",
        "    # TODO: Generate a response using the model. Ensure do_sample is False.\n",
        "    output = model.generate(input_ids, max_new_tokens=max_new_tokens, do_sample=False, attention_mask=inputs.attention_mask, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    # TODO: Decode the output and return the response without special tokens\n",
        "    assistant_response = tokenizer.decode(output[0, input_ids.shape[-1]+2:], skip_special_tokens=True).strip() # plus 2 because we need to get rid of text that says assistant\n",
        "    if verbose: print(\"\\n###response:###\\n\", assistant_response)\n",
        "    return assistant_response\n",
        "\n",
        "assistant_response = run_model(model=model, tokenizer=tokenizer, messages=messages, max_new_tokens=10, verbose=True)\n",
        "print(f\"\\n###Assistant response:###\\n{assistant_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHmnM3DmWrUG"
      },
      "source": [
        "Use the following code snippet to verify your implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "icc7-5CdWqzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0e780c-e745-42c5-8f11-131e6d60f8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your output is: University of California, Los Angeles (UCLA) was founded in 1919.\n",
            "The expected output is: University of California, Los Angeles (UCLA) was founded in 1919.\n",
            "Part 2.1.2 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell.\n",
        "grading_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a chatbot who responds very shortly.\"},\n",
        "    {\"role\": \"user\", \"content\": \"When was UCLA founded?\"},\n",
        "]\n",
        "grading_output = run_model(model=model, tokenizer=tokenizer, messages=grading_messages, max_new_tokens=100)\n",
        "expected_output = \"University of California, Los Angeles (UCLA) was founded in 1919.\"\n",
        "print(f\"Your output is: {grading_output}\\nThe expected output is: {expected_output}\")\n",
        "if grading_output != expected_output:\n",
        "    raise ValueError(f\"FAILED: Incorrect response! \\n\\n{grading_output}\\n\\n{expected_output}\")\n",
        "print(\"Part 2.1.2 passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwBJmIwDW4zB"
      },
      "source": [
        "### Section 2: Evaluation of the pre-trained model (15 points)\n",
        "In this section, we are going to evaluate the pre-trained model with the natural language inference (NLI) task. NLI is a fundamental task in natural language processing that involves determining the relationship between two sentences: a **premise** and a **hypothesis**. The task is to classify this relationship into one of three categories:\n",
        "\n",
        "**Entailment**: The hypothesis logically follows from the premise.\n",
        "\n",
        "**Contradiction**: The hypothesis is logically inconsistent with the premise.\n",
        "\n",
        "**Neutral**: This occurs when there is no clear logical relationship between the premise and the hypothesis.\n",
        "\n",
        "You can view examples for each category by running the cell below.\n",
        "\n",
        "Your task is to implement the evaluation code. This involves running the model on the test set and comparing its predictions with the true labels. The goal is to achieve an accuracy of at least 25% by prompt engineering the model to generate the appropriate labels for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "dk-GGUOlZezy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1d790ff8-149d-4026-c54f-c6bca0bc0c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                             premise  \\\n",
              "0                                                                                          A nighttime street scene of a restaurant.   \n",
              "1                                                                    A man wearing protective gear grinds down a large metal object.   \n",
              "2                                                                   A boy toddler is holding a bat he is about to swing at a pinata.   \n",
              "3                                                           A crowd of people at a county fair watch three men agitate a large bull.   \n",
              "4                                                                An older gentleman looks at the camera while he is building a deck.   \n",
              "..                                                                                                                               ...   \n",
              "195  A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.   \n",
              "196                        Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.   \n",
              "197                                                                  a young girl looking down through some leaves from atop a tree.   \n",
              "198                                   A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.   \n",
              "199                                                                                   Two kids running past a dinosaur in the woods.   \n",
              "\n",
              "                                                                         hypothesis  \\\n",
              "0                                       A nighttime scene of an apartment building.   \n",
              "1                                                           There is a man working.   \n",
              "2                                      A child is crying because he didn't get cake   \n",
              "3                                               A man rides horseback in the field.   \n",
              "4                             A human looks at the camera while building something.   \n",
              "..                                                                              ...   \n",
              "195                                                    A man is waiting for someone   \n",
              "196  Two women are staring at a mountain and neither has any headphones or jackets.   \n",
              "197                                              The girl is playing hide and seek.   \n",
              "198                                  A woman is wearing glasses and a brown beanie.   \n",
              "199                                              Young people are running outdoors.   \n",
              "\n",
              "             label  \n",
              "0    contradiction  \n",
              "1       entailment  \n",
              "2    contradiction  \n",
              "3    contradiction  \n",
              "4       entailment  \n",
              "..             ...  \n",
              "195        neutral  \n",
              "196  contradiction  \n",
              "197        neutral  \n",
              "198     entailment  \n",
              "199     entailment  \n",
              "\n",
              "[200 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0e9d0f7-e2db-442b-b3d6-d8376ff0915d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A nighttime street scene of a restaurant.</td>\n",
              "      <td>A nighttime scene of an apartment building.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A man wearing protective gear grinds down a large metal object.</td>\n",
              "      <td>There is a man working.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A boy toddler is holding a bat he is about to swing at a pinata.</td>\n",
              "      <td>A child is crying because he didn't get cake</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A crowd of people at a county fair watch three men agitate a large bull.</td>\n",
              "      <td>A man rides horseback in the field.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An older gentleman looks at the camera while he is building a deck.</td>\n",
              "      <td>A human looks at the camera while building something.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.</td>\n",
              "      <td>A man is waiting for someone</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.</td>\n",
              "      <td>Two women are staring at a mountain and neither has any headphones or jackets.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>a young girl looking down through some leaves from atop a tree.</td>\n",
              "      <td>The girl is playing hide and seek.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.</td>\n",
              "      <td>A woman is wearing glasses and a brown beanie.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Two kids running past a dinosaur in the woods.</td>\n",
              "      <td>Young people are running outdoors.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e9d0f7-e2db-442b-b3d6-d8376ff0915d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0e9d0f7-e2db-442b-b3d6-d8376ff0915d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0e9d0f7-e2db-442b-b3d6-d8376ff0915d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset[\\\"test\\\"]\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"premise\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 198,\n        \"samples\": [\n          \"Man jumping up in the air and splitting his legs with his mouth open.\",\n          \"A girl playfully kicks a guy in the face while another person makes faces.\",\n          \"Two men stand on stairs with an assortment of chairs and a woven basket in the foreground.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypothesis\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"The boys are young\",\n          \"A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag.\",\n          \"Two girls grin into the camera.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"contradiction\",\n          \"entailment\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "# Downloading dataset\n",
        "dataset = {\n",
        "    \"train\": pd.read_json(\"hf://datasets/marslabucla/CS263-nli/assignment_1/esnli_train.jsonl\", lines=True),\n",
        "    \"validation\": pd.read_json(\"hf://datasets/marslabucla/CS263-nli/assignment_1/esnli_validation.jsonl\", lines=True),\n",
        "    \"test\": pd.read_json(\"hf://datasets/marslabucla/CS263-nli/assignment_1/esnli_test.jsonl\", lines=True),\n",
        "}\n",
        "\n",
        "dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ks70OR2wZ-Pq"
      },
      "outputs": [],
      "source": [
        "def apply_esnli_prompt(premise, hypothesis):\n",
        "    # TODO:\n",
        "    # Write a prompt for esnli dataset using given premise and hypothesis\n",
        "    # so that the model classifies the input as entailment, neutral, or contradiction\n",
        "    prompt = f'''\n",
        "            Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\n",
        "            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\n",
        "            You need to figure out whether the hypothesis is entailment, neutral, or contradiction of the premise.\n",
        "            Please only output a single word, either: \"neutral\", \"entailment\", or \"contradiction\". DO NOT output any other text than one of the three categories.\n",
        "            Here are some examples:\n",
        "            Premise: A nighttime street scene of a restaurant. Hypothesis: A nighttime scene of an apartment building. Label: contradiction\n",
        "            Premise: A man wearing protective gear grinds down a large metal object. Hypothesis: There is a man working. Label: entailment\n",
        "            Premise: a young girl looking down through some leaves from atop a tree. Hypothesis: The girl is playing hide and seek. Label: neutral\n",
        "\n",
        "            Now here is the premise and hypothesis for you to categorize:\n",
        "\n",
        "            \\n\\nPremise: {premise}\n",
        "            \\n\\nHypothesis: {hypothesis}'''\n",
        "\n",
        "    return prompt.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "S7oVbn7JaH6w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "034c0831-ada2-4bd4-d579-fa6b9de622d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                             premise  \\\n",
              "0                                                                                          A nighttime street scene of a restaurant.   \n",
              "1                                                                    A man wearing protective gear grinds down a large metal object.   \n",
              "2                                                                   A boy toddler is holding a bat he is about to swing at a pinata.   \n",
              "3                                                           A crowd of people at a county fair watch three men agitate a large bull.   \n",
              "4                                                                An older gentleman looks at the camera while he is building a deck.   \n",
              "..                                                                                                                               ...   \n",
              "195  A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.   \n",
              "196                        Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.   \n",
              "197                                                                  a young girl looking down through some leaves from atop a tree.   \n",
              "198                                   A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.   \n",
              "199                                                                                   Two kids running past a dinosaur in the woods.   \n",
              "\n",
              "                                                                         hypothesis  \\\n",
              "0                                       A nighttime scene of an apartment building.   \n",
              "1                                                           There is a man working.   \n",
              "2                                      A child is crying because he didn't get cake   \n",
              "3                                               A man rides horseback in the field.   \n",
              "4                             A human looks at the camera while building something.   \n",
              "..                                                                              ...   \n",
              "195                                                    A man is waiting for someone   \n",
              "196  Two women are staring at a mountain and neither has any headphones or jackets.   \n",
              "197                                              The girl is playing hide and seek.   \n",
              "198                                  A woman is wearing glasses and a brown beanie.   \n",
              "199                                              Young people are running outdoors.   \n",
              "\n",
              "             label  \\\n",
              "0    contradiction   \n",
              "1       entailment   \n",
              "2    contradiction   \n",
              "3    contradiction   \n",
              "4       entailment   \n",
              "..             ...   \n",
              "195        neutral   \n",
              "196  contradiction   \n",
              "197        neutral   \n",
              "198     entailment   \n",
              "199     entailment   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               prompt  \n",
              "0                                                                                                       Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A nighttime street scene of a restaurant.\\n            \\n\\nHypothesis: A nighttime scene of an apartment building.  \n",
              "1                                                                                                     Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A man wearing protective gear grinds down a large metal object.\\n            \\n\\nHypothesis: There is a man working.  \n",
              "2                                                                               Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A boy toddler is holding a bat he is about to swing at a pinata.\\n            \\n\\nHypothesis: A child is crying because he didn't get cake  \n",
              "3                                                                                Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A crowd of people at a county fair watch three men agitate a large bull.\\n            \\n\\nHypothesis: A man rides horseback in the field.  \n",
              "4                                                                   Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: An older gentleman looks at the camera while he is building a deck.\\n            \\n\\nHypothesis: A human looks at the camera while building something.  \n",
              "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ...  \n",
              "195                              Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.\\n            \\n\\nHypothesis: A man is waiting for someone  \n",
              "196  Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.\\n            \\n\\nHypothesis: Two women are staring at a mountain and neither has any headphones or jackets.  \n",
              "197                                                                                        Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: a young girl looking down through some leaves from atop a tree.\\n            \\n\\nHypothesis: The girl is playing hide and seek.  \n",
              "198                                             Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.\\n            \\n\\nHypothesis: A woman is wearing glasses and a brown beanie.  \n",
              "199                                                                                                         Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: Two kids running past a dinosaur in the woods.\\n            \\n\\nHypothesis: Young people are running outdoors.  \n",
              "\n",
              "[200 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08ae6c7d-38c4-4bed-aff8-7de76ca6649e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A nighttime street scene of a restaurant.</td>\n",
              "      <td>A nighttime scene of an apartment building.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A nighttime street scene of a restaurant.\\n            \\n\\nHypothesis: A nighttime scene of an apartment building.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A man wearing protective gear grinds down a large metal object.</td>\n",
              "      <td>There is a man working.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A man wearing protective gear grinds down a large metal object.\\n            \\n\\nHypothesis: There is a man working.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A boy toddler is holding a bat he is about to swing at a pinata.</td>\n",
              "      <td>A child is crying because he didn't get cake</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A boy toddler is holding a bat he is about to swing at a pinata.\\n            \\n\\nHypothesis: A child is crying because he didn't get cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A crowd of people at a county fair watch three men agitate a large bull.</td>\n",
              "      <td>A man rides horseback in the field.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A crowd of people at a county fair watch three men agitate a large bull.\\n            \\n\\nHypothesis: A man rides horseback in the field.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An older gentleman looks at the camera while he is building a deck.</td>\n",
              "      <td>A human looks at the camera while building something.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: An older gentleman looks at the camera while he is building a deck.\\n            \\n\\nHypothesis: A human looks at the camera while building something.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.</td>\n",
              "      <td>A man is waiting for someone</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.\\n            \\n\\nHypothesis: A man is waiting for someone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.</td>\n",
              "      <td>Two women are staring at a mountain and neither has any headphones or jackets.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.\\n            \\n\\nHypothesis: Two women are staring at a mountain and neither has any headphones or jackets.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>a young girl looking down through some leaves from atop a tree.</td>\n",
              "      <td>The girl is playing hide and seek.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: a young girl looking down through some leaves from atop a tree.\\n            \\n\\nHypothesis: The girl is playing hide and seek.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.</td>\n",
              "      <td>A woman is wearing glasses and a brown beanie.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.\\n            \\n\\nHypothesis: A woman is wearing glasses and a brown beanie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Two kids running past a dinosaur in the woods.</td>\n",
              "      <td>Young people are running outdoors.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \"entailment\", \"neutral\", or \"contradiction\". DO NOT output any other text.\\n            \\n\\nPremise: Two kids running past a dinosaur in the woods.\\n            \\n\\nHypothesis: Young people are running outdoors.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows  4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08ae6c7d-38c4-4bed-aff8-7de76ca6649e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08ae6c7d-38c4-4bed-aff8-7de76ca6649e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08ae6c7d-38c4-4bed-aff8-7de76ca6649e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"prompt_dataset[\\\"test\\\"]\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"premise\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 198,\n        \"samples\": [\n          \"Man jumping up in the air and splitting his legs with his mouth open.\",\n          \"A girl playfully kicks a guy in the face while another person makes faces.\",\n          \"Two men stand on stairs with an assortment of chairs and a woven basket in the foreground.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypothesis\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"The boys are young\",\n          \"A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag.\",\n          \"Two girls grin into the camera.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"contradiction\",\n          \"entailment\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \\\"entailment\\\", \\\"neutral\\\", or \\\"contradiction\\\". DO NOT output any other text.\\n            \\n\\nPremise: Three young boys enjoying a day at the beach.\\n            \\n\\nHypothesis: The boys are young\",\n          \"Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \\\"entailment\\\", \\\"neutral\\\", or \\\"contradiction\\\". DO NOT output any other text.\\n            \\n\\nPremise: A man in a black shirt, in a commercial kitchen, holding up meat he took out of a bag.\\n            \\n\\nHypothesis: A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag.\",\n          \"Please classify the following premise and hypothesis as entailment, neutral, or contradiction. Entailment means The hypothesis logically follows from the premise.\\n            Contradiction means the hypothesis is logically inconsistent with the premise. And neutral means there is no clear logical relationship between the premise and the hypothesis.\\n            Please only output a single word, either \\\"entailment\\\", \\\"neutral\\\", or \\\"contradiction\\\". DO NOT output any other text.\\n            \\n\\nPremise: Two girls looking into camera and smiling\\n            \\n\\nHypothesis: Two girls grin into the camera.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Applying your prompt template on the dataset\n",
        "prompt_dataset = {}\n",
        "for part in dataset.keys():\n",
        "    prompt_dataset[part] = dataset[part].copy()\n",
        "    prompt_dataset[part][\"prompt\"] = prompt_dataset[part].apply(lambda x: apply_esnli_prompt(x[\"premise\"], x[\"hypothesis\"]), axis=1)\n",
        "prompt_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "MVGDqanEafxI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate_esnli(model, tokenizer, test_dataset):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset.\n",
        "    Returns:\n",
        "        accuracy: The accuracy of the model on the test dataset. The value is scaled from 0.0 to 1.0 (float)\n",
        "        outputs: The model's predictions on the test dataset. (list[str])\n",
        "    \"\"\"\n",
        "    # TODO: Implement the evaluation loop and return accuracy of the model as well as list of outputs\n",
        "    # Hint: You can reuse the run_model function we implemented earlier.\n",
        "    outputs = test_dataset.apply(lambda x: run_model(model, tokenizer, [{\"role\": \"user\", \"content\": x[\"prompt\"]}], max_new_tokens=20), axis=1)\n",
        "    labels = test_dataset[\"label\"]\n",
        "    accuracy = accuracy_score(labels, outputs.str.lower())\n",
        "\n",
        "    return accuracy, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "qkp0iqXKayZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad57af4-fcf9-4dd0-8eb7-5690ac8e260e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      entailment\n",
            "1      entailment\n",
            "2      entailment\n",
            "3      entailment\n",
            "4      entailment\n",
            "          ...    \n",
            "195    entailment\n",
            "196    entailment\n",
            "197    entailment\n",
            "198    Entailment\n",
            "199    entailment\n",
            "Length: 200, dtype: object 0      contradiction\n",
            "1         entailment\n",
            "2      contradiction\n",
            "3      contradiction\n",
            "4         entailment\n",
            "           ...      \n",
            "195          neutral\n",
            "196    contradiction\n",
            "197          neutral\n",
            "198       entailment\n",
            "199       entailment\n",
            "Name: label, Length: 200, dtype: object\n",
            "Accuracy: 0.345\n",
            "Part 2.2.1 passed\n",
            "Part 2.2.2 passed\n"
          ]
        }
      ],
      "source": [
        "# DO NOT alter this cell:\n",
        "acc, outputs = evaluate_esnli(model, tokenizer, prompt_dataset[\"test\"])\n",
        "print(f\"Accuracy: {acc}\")\n",
        "prompt_dataset[\"test\"][\"output\"] = outputs\n",
        "expected_acc = 0.25\n",
        "if acc < expected_acc / 2 or acc > 1:\n",
        "  raise ValueError(f\"FAILED: Low Accuracy! \\n\\n{acc} is lower than the required threshold 0.25\\nYou might need to update your prompt so that the model follows the instructions better.\")\n",
        "print(\"Part 2.2.1 passed\")\n",
        "\n",
        "if acc < expected_acc or acc > 1:\n",
        "    raise ValueError(f\"FAILED: Low Accuracy! \\n\\n{acc} is lower than the required threshold {expected_acc}\\nYou might need to update your prompt so that the model follows the instructions better.\")\n",
        "print(\"Part 2.2.2 passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETw_Y7kXQurU"
      },
      "source": [
        "### Section 3: NLI with Explanations (15 points)\n",
        "\n",
        "\n",
        "* In this section, you'll use the e-SNLI dataset, which includes free-form rationales (explanations) for each NLI example. The task is to generate model explanations for a subset of the test set and compare them to human explanations using the BLEU score. Your primary task is to write effective prompts that will guide the model to generate explanations for a subset of the test set.\n",
        "\n",
        "* Expectations:\n",
        "    * Pretrained Model: Expected BLEU score > 0.15.\n",
        "\n",
        "* To improve the model's explanations, you'll need to engage in prompt engineering. Adjust your input prompts to guide the model toward better explanations (More similar to human references) and aim to improve the BLEU score. You are also encouraged to check the generated explanations to qualitatively understand their quality, and possibly conduct some analysis.\n",
        "\n",
        "* By the end of this section, you should be able to create effective prompts that improve the quality of the model's explanations and analyze their performance through BLEU scores, and optionally do a qualitative analysis by reviewing the explanations and comparing them with human-provided ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "dnxOA-hlQpBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3bfa10a-dcc6-4550-d211-9815cc392a0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                             premise  \\\n",
              "0                                                                                          A nighttime street scene of a restaurant.   \n",
              "1                                                                    A man wearing protective gear grinds down a large metal object.   \n",
              "2                                                                   A boy toddler is holding a bat he is about to swing at a pinata.   \n",
              "3                                                           A crowd of people at a county fair watch three men agitate a large bull.   \n",
              "4                                                                An older gentleman looks at the camera while he is building a deck.   \n",
              "..                                                                                                                               ...   \n",
              "195  A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.   \n",
              "196                        Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.   \n",
              "197                                                                  a young girl looking down through some leaves from atop a tree.   \n",
              "198                                   A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.   \n",
              "199                                                                                   Two kids running past a dinosaur in the woods.   \n",
              "\n",
              "                                                                         hypothesis  \\\n",
              "0                                       A nighttime scene of an apartment building.   \n",
              "1                                                           There is a man working.   \n",
              "2                                      A child is crying because he didn't get cake   \n",
              "3                                               A man rides horseback in the field.   \n",
              "4                             A human looks at the camera while building something.   \n",
              "..                                                                              ...   \n",
              "195                                                    A man is waiting for someone   \n",
              "196  Two women are staring at a mountain and neither has any headphones or jackets.   \n",
              "197                                              The girl is playing hide and seek.   \n",
              "198                                  A woman is wearing glasses and a brown beanie.   \n",
              "199                                              Young people are running outdoors.   \n",
              "\n",
              "             label  \\\n",
              "0    contradiction   \n",
              "1       entailment   \n",
              "2    contradiction   \n",
              "3    contradiction   \n",
              "4       entailment   \n",
              "..             ...   \n",
              "195        neutral   \n",
              "196  contradiction   \n",
              "197        neutral   \n",
              "198     entailment   \n",
              "199     entailment   \n",
              "\n",
              "                                                                                                                                                                                                                           explanation_1  \\\n",
              "0                                                                                                                                                                      The scene is of a restaurant, which is not an apartment building.   \n",
              "1                                                                                                                                                                                                           Grinds down implies working.   \n",
              "2                                                                                                                                                                                       A toddler can be either holding a bat or crying.   \n",
              "3                                                                                                                                                                                                    Three men is not the same as a man.   \n",
              "4                                                                                                                                                                                                 An older gentleman is a human as well.   \n",
              "..                                                                                                                                                                                                                                   ...   \n",
              "195                                                                                                                                                             Sitting against a wall does not imply that a man is waiting for someone.   \n",
              "196  He refers to two men not two women. They cannot be looking out over some water and staring at a mountain simultaneously. If neither has any headphones or jackets then they cannot be wearing red jackets or have yellow earphones.   \n",
              "197                                                                                                                                     A girl looking down trough some leaves from atop a tree doesn't imply that the girl is playing .   \n",
              "198                                                                                                                                                                                            A woman is next to a girl holding a book.   \n",
              "199                                                                                                                                                                                                              The woods are outdoors.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                             explanation_2  \\\n",
              "0                                                                                                                                                                                                                              Scene can't be of apartment building if it is a restaurant.   \n",
              "1                                                                                                                                                                                                                           Grinding down a large metal object implies the man is working.   \n",
              "2    A boy toddler indicates the gender is male and the age is 1-3 years old whereas a child could be male or female and up to 12 or 13 years of age generally. Holding a bat to swing at a pinata implies the child is happy and having fun whereas crying implies that the child is sad.   \n",
              "3                                                                                                                                                                                                          Three men agitate a large bull is not the same as a single man rides horseback.   \n",
              "4                                                                                                                                                                                                                                           If it is a man, or gentleman, that is a human.   \n",
              "..                                                                                                                                                                                                                                                                                     ...   \n",
              "195                                                                                                                                                                                                                                               The man might not be waiting for anyone.   \n",
              "196                                                                                                                                                                                                                                      Women are not men.  Headphones are not earphones.   \n",
              "197                                                                                                                                                                                                           The girl looking down from the tree may not be playing hide and seek at all.   \n",
              "198                                                                                                                                                                                                                     The woman is dressed the same, wearing glasses and a brown beanie.   \n",
              "199                                                                                                                                                                                                                                                         The two kids are young people.   \n",
              "\n",
              "                                                                                                                                  explanation_3  \n",
              "0                                                                                The scene can be either an apartment building or a restaurant.  \n",
              "1                                                                                  The man is working by grinding down on a large metal object.  \n",
              "2                                                         A boy that is about to swing at a pinata cannot be crying because he didn't get cake.  \n",
              "3                                   There is only one man riding horseback in a field not a crowd of people at a county fair with a large bull.  \n",
              "4                                                                                            The creature is a human because he is a gentleman.  \n",
              "..                                                                                                                                          ...  \n",
              "195                                              It is possible that someone is already present and therefore man is not in the act of waiting.  \n",
              "196  two men looking out over some water one man having yellow earphone is not same as two men staring at a mountain neither has any headphones  \n",
              "197                                                A young girl may look down through leaves for many reasons other than playing hide and seek.  \n",
              "198                                       A woman wearing glasses and a brown beanie is the same as a woman wearing glasses and a brown beanie.  \n",
              "199                                                                                      Two kids are young people, and the woods are outdoors.  \n",
              "\n",
              "[200 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad16291f-f396-466a-bf4f-fe744fab7d56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>explanation_1</th>\n",
              "      <th>explanation_2</th>\n",
              "      <th>explanation_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A nighttime street scene of a restaurant.</td>\n",
              "      <td>A nighttime scene of an apartment building.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>The scene is of a restaurant, which is not an apartment building.</td>\n",
              "      <td>Scene can't be of apartment building if it is a restaurant.</td>\n",
              "      <td>The scene can be either an apartment building or a restaurant.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A man wearing protective gear grinds down a large metal object.</td>\n",
              "      <td>There is a man working.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Grinds down implies working.</td>\n",
              "      <td>Grinding down a large metal object implies the man is working.</td>\n",
              "      <td>The man is working by grinding down on a large metal object.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A boy toddler is holding a bat he is about to swing at a pinata.</td>\n",
              "      <td>A child is crying because he didn't get cake</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>A toddler can be either holding a bat or crying.</td>\n",
              "      <td>A boy toddler indicates the gender is male and the age is 1-3 years old whereas a child could be male or female and up to 12 or 13 years of age generally. Holding a bat to swing at a pinata implies the child is happy and having fun whereas crying implies that the child is sad.</td>\n",
              "      <td>A boy that is about to swing at a pinata cannot be crying because he didn't get cake.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A crowd of people at a county fair watch three men agitate a large bull.</td>\n",
              "      <td>A man rides horseback in the field.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Three men is not the same as a man.</td>\n",
              "      <td>Three men agitate a large bull is not the same as a single man rides horseback.</td>\n",
              "      <td>There is only one man riding horseback in a field not a crowd of people at a county fair with a large bull.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An older gentleman looks at the camera while he is building a deck.</td>\n",
              "      <td>A human looks at the camera while building something.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>An older gentleman is a human as well.</td>\n",
              "      <td>If it is a man, or gentleman, that is a human.</td>\n",
              "      <td>The creature is a human because he is a gentleman.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>A shirtless man with a white hat and no shoes sitting crisscross with his back against the wall holding up a white plastic cup.</td>\n",
              "      <td>A man is waiting for someone</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Sitting against a wall does not imply that a man is waiting for someone.</td>\n",
              "      <td>The man might not be waiting for anyone.</td>\n",
              "      <td>It is possible that someone is already present and therefore man is not in the act of waiting.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Two men wearing red jackets are looking out over some water and one man has yellow earphones on his ears.</td>\n",
              "      <td>Two women are staring at a mountain and neither has any headphones or jackets.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>He refers to two men not two women. They cannot be looking out over some water and staring at a mountain simultaneously. If neither has any headphones or jackets then they cannot be wearing red jackets or have yellow earphones.</td>\n",
              "      <td>Women are not men.  Headphones are not earphones.</td>\n",
              "      <td>two men looking out over some water one man having yellow earphone is not same as two men staring at a mountain neither has any headphones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>a young girl looking down through some leaves from atop a tree.</td>\n",
              "      <td>The girl is playing hide and seek.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>A girl looking down trough some leaves from atop a tree doesn't imply that the girl is playing .</td>\n",
              "      <td>The girl looking down from the tree may not be playing hide and seek at all.</td>\n",
              "      <td>A young girl may look down through leaves for many reasons other than playing hide and seek.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>A woman wearing glasses and a brown beanie next to a girl with long brown hair holding a book.</td>\n",
              "      <td>A woman is wearing glasses and a brown beanie.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>A woman is next to a girl holding a book.</td>\n",
              "      <td>The woman is dressed the same, wearing glasses and a brown beanie.</td>\n",
              "      <td>A woman wearing glasses and a brown beanie is the same as a woman wearing glasses and a brown beanie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Two kids running past a dinosaur in the woods.</td>\n",
              "      <td>Young people are running outdoors.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>The woods are outdoors.</td>\n",
              "      <td>The two kids are young people.</td>\n",
              "      <td>Two kids are young people, and the woods are outdoors.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows  6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad16291f-f396-466a-bf4f-fe744fab7d56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad16291f-f396-466a-bf4f-fe744fab7d56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad16291f-f396-466a-bf4f-fe744fab7d56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_45893585-4630-4a42-98e3-c9ba2972f3db\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('explanation_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_45893585-4630-4a42-98e3-c9ba2972f3db button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('explanation_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "explanation_dataset",
              "summary": "{\n  \"name\": \"explanation_dataset\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"premise\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 198,\n        \"samples\": [\n          \"Man jumping up in the air and splitting his legs with his mouth open.\",\n          \"A girl playfully kicks a guy in the face while another person makes faces.\",\n          \"Two men stand on stairs with an assortment of chairs and a woven basket in the foreground.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypothesis\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"The boys are young\",\n          \"A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag.\",\n          \"Two girls grin into the camera.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"contradiction\",\n          \"entailment\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"Young boys are boys that are young.\",\n          \"The meat does not have to be old.\",\n          \"Grinning is a form of smiling.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"The boys young refers to three young boys enjoying a day at the beach.\",\n          \"the meat may not be old can be fresh\",\n          \"Grin is a synonym for smiling.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation_3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"Boys who are young enjoy a day at the beach.\",\n          \"Not all meat in a bag is old meat.\",\n          \"\\\"Grinning into the camera\\\" is a rephrasing of \\\"smiling into the camera\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "explanation_dataset = pd.read_json(\"hf://datasets/marslabucla/CS263-nli/assignment_1/esnli_test_with_explanation.jsonl\", lines=True)\n",
        "explanation_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5UzvkotQ8y3"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def apply_esnli_prompt_explanation(premise, hypothesis):\n",
        "    # TODO:\n",
        "    # Create a prompt for the e-SNLI dataset.\n",
        "    # This prompt will guide the model to generate an explanation for the relationship\n",
        "    # between the given premise and hypothesis.\n",
        "\n",
        "    return prompt.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8ti61DDbjyA"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "def evaluate_esnli_explanation(model, tokenizer, test_dataset, max_new_tokens=1000):\n",
        "    outputs = []\n",
        "    for row in tqdm(test_dataset.to_dict(orient=\"records\")):\n",
        "        # Construct the messages to send to the model.\n",
        "        grading_messages = [\n",
        "            {\"role\": \"system\", \"content\": \"\"},\n",
        "            {\"role\": \"user\", \"content\": row[\"prompt\"]},\n",
        "        ]\n",
        "        # Run the model with the constructed messages and store the output.\n",
        "        output = run_model(model=model, tokenizer=tokenizer, messages=grading_messages, max_new_tokens=max_new_tokens)\n",
        "        # print(output)\n",
        "        outputs.append(output)\n",
        "    # Initialize lists to hold references and hypotheses for BLEU score calculation.\n",
        "    r, h = [], []\n",
        "    for idx, row in tqdm(enumerate(test_dataset.to_dict(orient=\"records\"))):\n",
        "        # Get the human-provided explanations (references) from the dataset.\n",
        "        references = [\n",
        "            row[\"explanation_1\"].split(),  # Split into list of words\n",
        "            row[\"explanation_2\"].split(),\n",
        "            row[\"explanation_3\"].split(),\n",
        "        ]\n",
        "        # Split the generated output (hypothesis) into words.\n",
        "        hypothesis = outputs[idx].split()\n",
        "        r.append(references)\n",
        "        h.append(hypothesis)\n",
        "\n",
        "    # Calculate the BLEU score using the nltk library.\n",
        "    # weights=(1, 0, 0, 0) means we are using only the 1-gram BLEU score.\n",
        "    bleu_score = nltk.translate.bleu_score.corpus_bleu(r, h, weights=(1, 0, 0, 0))\n",
        "    return bleu_score, outputs  # Return the calculated BLEU score and the generated outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm-1T765RLbY"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE (Testing Pre-trained Model)\n",
        "prompt_explanation_dataset = {}\n",
        "prompt_explanation_dataset[\"test\"] = explanation_dataset.copy()\n",
        "prompt_explanation_dataset[\"test\"][\"prompt\"] = prompt_explanation_dataset[\"test\"].apply(lambda x: apply_esnli_prompt_explanation(x[\"premise\"], x[\"hypothesis\"]), axis=1)\n",
        "prompt_explanation_dataset[\"test\"]\n",
        "\n",
        "df = prompt_explanation_dataset[\"test\"].iloc[:10].copy()\n",
        "bleu_score, outputs = evaluate_esnli_explanation(model, tokenizer, df)\n",
        "print(f\"Bleu: {bleu_score}\")\n",
        "df[\"output\"] = outputs\n",
        "display(df)\n",
        "expected_bleu = 0.15\n",
        "if bleu_score < expected_bleu:\n",
        "    raise ValueError(f\"FAILED: Low Bleu! \\n\\n{bleu_score} is lower than the required threshold {expected_bleu}\\nYou might need to update your prompt so that the model explains more similarly to human explanations.\")\n",
        "print(\"Part 2.3 passed\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "30zB9u-AnQ_0",
        "TpgNAKEFKHGU",
        "DC3jVajnLouW",
        "pS564L27evsM",
        "6658EdvQShfK",
        "BOnP7pO6WSre",
        "wwBJmIwDW4zB",
        "ETw_Y7kXQurU"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "CS263-HW1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef06769e84974f6ebe27d54d065a7a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_fe05f816a09944e98b0abfc9829a8527"
          }
        },
        "c0b53130974843e69b74aa3952294ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ef54dd3d8e42c4be9e8aedcd80005b",
            "placeholder": "",
            "style": "IPY_MODEL_5f0c5d6bde5445f59d1d5d61a4f60fa6",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e0e890eeef164c11ada76c061b4d58f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_baf398c454a54fe7949f2b9f75be797d",
            "placeholder": "",
            "style": "IPY_MODEL_b0115269912b44ddb41bf3ac729c09b1",
            "value": ""
          }
        },
        "540d59488b4d4685bddadac03b20f67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f42247b447dd432ba127f37ab68039a5",
            "style": "IPY_MODEL_7db3de040d594f4ebcf6b174ef96f432",
            "value": true
          }
        },
        "c0adb79942a7448282c74e1c5d7c70bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_212e161484b54607b60b9af8b1b34e9c",
            "style": "IPY_MODEL_34c0a5d2c2e84cbd8465d2f7a6fb6f03",
            "tooltip": ""
          }
        },
        "2560557b97824838a4082904c642e331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412138868d7744bd885441c5436f051e",
            "placeholder": "",
            "style": "IPY_MODEL_d144d3d180fe4ceca0040eb923c67341",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "fe05f816a09944e98b0abfc9829a8527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "32ef54dd3d8e42c4be9e8aedcd80005b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0c5d6bde5445f59d1d5d61a4f60fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf398c454a54fe7949f2b9f75be797d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0115269912b44ddb41bf3ac729c09b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f42247b447dd432ba127f37ab68039a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db3de040d594f4ebcf6b174ef96f432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "212e161484b54607b60b9af8b1b34e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c0a5d2c2e84cbd8465d2f7a6fb6f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "412138868d7744bd885441c5436f051e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d144d3d180fe4ceca0040eb923c67341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d049b709c25444c970e21d66f88abed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1993c46a31a64b868d4012bc8cee2de5",
            "placeholder": "",
            "style": "IPY_MODEL_ca796eb5797e470c9cb1a70dc221d81f",
            "value": "Connecting..."
          }
        },
        "1993c46a31a64b868d4012bc8cee2de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca796eb5797e470c9cb1a70dc221d81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d70dfa7f27e45fea8404b83d01ea9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7a8ad94cbc44ef89e2cdaa547648fec",
              "IPY_MODEL_4ca7c35209e541f483b20d013b76903d",
              "IPY_MODEL_b686f075d1d0430e845c317137510750"
            ],
            "layout": "IPY_MODEL_7642a27daaee4d64aad86957a3be786e"
          }
        },
        "d7a8ad94cbc44ef89e2cdaa547648fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bd8f9fb7834523a221e1670fe048cd",
            "placeholder": "",
            "style": "IPY_MODEL_7b4c3d0654d34862846c6c45e5887885",
            "value": "config.json:100%"
          }
        },
        "4ca7c35209e541f483b20d013b76903d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c430fbb2ae464bbd40c3349ef49e5a",
            "max": 877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51d2aac7fab64fe3bfdad055a65cb8cf",
            "value": 877
          }
        },
        "b686f075d1d0430e845c317137510750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d4e08473fe41d0835da8fbc0488206",
            "placeholder": "",
            "style": "IPY_MODEL_189cf80766b242359f0ecac8614389b0",
            "value": "877/877[00:00&lt;00:00,87.3kB/s]"
          }
        },
        "7642a27daaee4d64aad86957a3be786e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91bd8f9fb7834523a221e1670fe048cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4c3d0654d34862846c6c45e5887885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c430fbb2ae464bbd40c3349ef49e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d2aac7fab64fe3bfdad055a65cb8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4d4e08473fe41d0835da8fbc0488206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189cf80766b242359f0ecac8614389b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed8dd6693f4444bb512e83c0285a5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e5299d524ae4893bba196270a10070b",
              "IPY_MODEL_323234ba73d44aa68f1d260b525701a6",
              "IPY_MODEL_b146a20fcccb4f2e92b4a240098ac460"
            ],
            "layout": "IPY_MODEL_554a80ae82374177a0e2344463706da6"
          }
        },
        "9e5299d524ae4893bba196270a10070b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0624136905f45c0b34e5d7992016a90",
            "placeholder": "",
            "style": "IPY_MODEL_d169c56354ca49a3a86d65c360faf777",
            "value": "model.safetensors:100%"
          }
        },
        "323234ba73d44aa68f1d260b525701a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9926167ce8854b01a000cc9c263f4f9f",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66486d00f6544439bda1fa57d5f66cf9",
            "value": 2471645608
          }
        },
        "b146a20fcccb4f2e92b4a240098ac460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb87c5d9f4d14676ad2e362eefd1014e",
            "placeholder": "",
            "style": "IPY_MODEL_7a9c9971d750433f92007b741cf139c1",
            "value": "2.47G/2.47G[02:55&lt;00:00,2.36MB/s]"
          }
        },
        "554a80ae82374177a0e2344463706da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0624136905f45c0b34e5d7992016a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d169c56354ca49a3a86d65c360faf777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9926167ce8854b01a000cc9c263f4f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66486d00f6544439bda1fa57d5f66cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb87c5d9f4d14676ad2e362eefd1014e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9c9971d750433f92007b741cf139c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9993f055ff3b4dc585e134a022fc44b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba25ac6cbf2f47d0a099bcb18c1c839d",
              "IPY_MODEL_f5f6f5f1bcd148cba7b215d9f9c98001",
              "IPY_MODEL_9b1101b480cf4ca3a3d45a887a4f694d"
            ],
            "layout": "IPY_MODEL_00cd50c6d8a742e290833103ddc1a82c"
          }
        },
        "ba25ac6cbf2f47d0a099bcb18c1c839d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2bae76ffb8e423e8fac29c0abced9ee",
            "placeholder": "",
            "style": "IPY_MODEL_79dcaa951c5b4af1ad43aee05745579c",
            "value": "generation_config.json:100%"
          }
        },
        "f5f6f5f1bcd148cba7b215d9f9c98001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb3fefe8a444a7887587d556d50fe63",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fec93d20ddfb488c88b0b52c5c822e4b",
            "value": 189
          }
        },
        "9b1101b480cf4ca3a3d45a887a4f694d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b586e4ebfa54f9c8d142fc9ce2dc6d9",
            "placeholder": "",
            "style": "IPY_MODEL_944932c577144063a4030d8de566ef2a",
            "value": "189/189[00:00&lt;00:00,20.5kB/s]"
          }
        },
        "00cd50c6d8a742e290833103ddc1a82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bae76ffb8e423e8fac29c0abced9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79dcaa951c5b4af1ad43aee05745579c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb3fefe8a444a7887587d556d50fe63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec93d20ddfb488c88b0b52c5c822e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b586e4ebfa54f9c8d142fc9ce2dc6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944932c577144063a4030d8de566ef2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78de7e6563f64399ad2ca7fe751170d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16b8e8f2364c4d7084a7db22cfcc16c2",
              "IPY_MODEL_ab6aafe4856b498f90d3809bb8de97ea",
              "IPY_MODEL_91425cf1000049c3877e5470a7e26ac9"
            ],
            "layout": "IPY_MODEL_2a7960d5b5794bc49d40e8a964cc2798"
          }
        },
        "16b8e8f2364c4d7084a7db22cfcc16c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1247174e2cf4457ba13ff7659cf1f3e2",
            "placeholder": "",
            "style": "IPY_MODEL_e08c0bf1d3d14bc9ab56e303af78db85",
            "value": "tokenizer_config.json:100%"
          }
        },
        "ab6aafe4856b498f90d3809bb8de97ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d40bec53dd646ecb37bb45ac6dc31d4",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e888581642240d7b9f3141e05a10bc1",
            "value": 54528
          }
        },
        "91425cf1000049c3877e5470a7e26ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac35af37262426e96a4d1559f995e37",
            "placeholder": "",
            "style": "IPY_MODEL_c4ab5a6c17684a0ab119d6de30fc069a",
            "value": "54.5k/54.5k[00:00&lt;00:00,3.33MB/s]"
          }
        },
        "2a7960d5b5794bc49d40e8a964cc2798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1247174e2cf4457ba13ff7659cf1f3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08c0bf1d3d14bc9ab56e303af78db85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d40bec53dd646ecb37bb45ac6dc31d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e888581642240d7b9f3141e05a10bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ac35af37262426e96a4d1559f995e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ab5a6c17684a0ab119d6de30fc069a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07d0c0f036b4f6786d56ca37511f574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37b711afd13b46eba2a0b5388c269fcb",
              "IPY_MODEL_bf34a095d0cf49858636ffb6a5cccec7",
              "IPY_MODEL_5881e3b5df30436abe1f0f3a98689efc"
            ],
            "layout": "IPY_MODEL_eb639ccb8a194d8b8e511fa7ae992bcf"
          }
        },
        "37b711afd13b46eba2a0b5388c269fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9be5d22167c4d16a69754d225b7e63a",
            "placeholder": "",
            "style": "IPY_MODEL_0abe1eb5e74b4014b1f7732654218425",
            "value": "tokenizer.json:100%"
          }
        },
        "bf34a095d0cf49858636ffb6a5cccec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55af65032c44427daded4bd953a3a5e4",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7efe83180a19491e95979f4e760ddf3c",
            "value": 9085657
          }
        },
        "5881e3b5df30436abe1f0f3a98689efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b9ffa2d7fd4835a5c67edec3c2aeed",
            "placeholder": "",
            "style": "IPY_MODEL_2806c53e8b874d86a136148be4e854a7",
            "value": "9.09M/9.09M[00:01&lt;00:00,7.29MB/s]"
          }
        },
        "eb639ccb8a194d8b8e511fa7ae992bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9be5d22167c4d16a69754d225b7e63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0abe1eb5e74b4014b1f7732654218425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55af65032c44427daded4bd953a3a5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efe83180a19491e95979f4e760ddf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84b9ffa2d7fd4835a5c67edec3c2aeed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2806c53e8b874d86a136148be4e854a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff5e8b6ae015417ca04395a8ad2ef3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_538b2d8e900f48cf93aec9d9d8dd3ae7",
              "IPY_MODEL_2bbd077e13ef4596a7e0127b429e70a8",
              "IPY_MODEL_d47b7c787a3d479ab196ab8f96b49804"
            ],
            "layout": "IPY_MODEL_e1f8820df7a44e199ed60a60141ea2ce"
          }
        },
        "538b2d8e900f48cf93aec9d9d8dd3ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a917102eaa142c685d2e8a0a03e8809",
            "placeholder": "",
            "style": "IPY_MODEL_a0c2cefc18cb4ff99fa2e31c44983e8e",
            "value": "special_tokens_map.json:100%"
          }
        },
        "2bbd077e13ef4596a7e0127b429e70a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a210f3cfde044d1c99fd69fcac6d0fbd",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_143ccd51bf1240a08c8389248eb12e66",
            "value": 296
          }
        },
        "d47b7c787a3d479ab196ab8f96b49804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374c960422b24aa68fd1703e2ef41462",
            "placeholder": "",
            "style": "IPY_MODEL_5e950ca4f60146d88f4336b67c6a0976",
            "value": "296/296[00:00&lt;00:00,34.3kB/s]"
          }
        },
        "e1f8820df7a44e199ed60a60141ea2ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a917102eaa142c685d2e8a0a03e8809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c2cefc18cb4ff99fa2e31c44983e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a210f3cfde044d1c99fd69fcac6d0fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143ccd51bf1240a08c8389248eb12e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "374c960422b24aa68fd1703e2ef41462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e950ca4f60146d88f4336b67c6a0976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}